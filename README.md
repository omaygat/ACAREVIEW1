#  Revisor AutomÃ¡tico de Escritura AcadÃ©mica

El **Revisor AutomÃ¡tico de Escritura AcadÃ©mica** es una aplicaciÃ³n que analiza textos acadÃ©micos para detectar errores ortogrÃ¡ficos, sugerir mejoras de estilo y validar las referencias.  
El proyecto estÃ¡ dividido en **frontend** (interfaz de usuario) y **backend** (procesamiento y lÃ³gica).

---

## ğŸ“ Estructura del proyecto

```
acareview/
â”œâ”€â”€ backend/        # API principal: validaciones, anÃ¡lisis de texto, conexiÃ³n con base de datos
â”œâ”€â”€ frontend/       # Interfaz de usuario construida con React + TailwindCSS
â”œâ”€â”€ tests/          # Pruebas unitarias y de integraciÃ³n (Jest)
â”œâ”€â”€ README.md       # DocumentaciÃ³n del proyecto
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml  # AutomatizaciÃ³n CI/CD con GitHub Actions
```

---

## âš™ï¸ TecnologÃ­as principales

| Componente | TecnologÃ­a |
|-------------|-------------|
| **Frontend** | React + TailwindCSS |
| **Backend** | Node.js + Express |
| **Pruebas** | Jest |
| **CI/CD** | GitHub Actions |
| **Cobertura** | Jest + Codecov |

---

## ğŸš€ InstalaciÃ³n y ejecuciÃ³n

1. Clona el repositorio:
   ```bash
   git clone https://github.com/usuario/acareview.git
   cd acareview
   ```

2. Instala dependencias:
   ```bash
   npm install
   ```

3. Ejecuta el proyecto:
   ```bash
   npm run dev
   ```

---

## ğŸ§ª EjecuciÃ³n de pruebas

Para correr los tests localmente:
```bash
npm test
```

Las pruebas se ejecutan automÃ¡ticamente con cada **push** o **pull request** gracias a **GitHub Actions**.

---

## ğŸ§° CI/CD y AutomatizaciÃ³n

Este proyecto incluye un pipeline de **IntegraciÃ³n Continua (CI)** que:

- Ejecuta los tests automÃ¡ticamente con cada commit.  
- Reporta la **cobertura de cÃ³digo**.  
- Muestra el estado de los tests en este README mediante **badges**.  
- Realiza **checks automÃ¡ticos en los pull requests**.

---

## ğŸ“Š Estado del Proyecto

![Build](https://github.com/usuario/acareview/actions/workflows/ci.yml/badge.svg)
[![codecov](https://codecov.io/gh/usuario/acareview/branch/main/graph/badge.svg)](https://codecov.io/gh/usuario/acareview)

---

## ğŸ“„ Ejemplo de uso

En el frontend puedes ingresar un texto acadÃ©mico.  
El sistema analiza el contenido y muestra:

- Errores ortogrÃ¡ficos detectados.  
- Recomendaciones de estilo.  
- VerificaciÃ³n de citas y referencias.  

---

## ğŸ’¡ OrganizaciÃ³n del cÃ³digo

- **`backend/`** â†’ Controladores, rutas y validadores.  
- **`frontend/`** â†’ Componentes de interfaz, vistas y lÃ³gica de interacciÃ³n.  
- **`tests/`** â†’ Archivos `.test.js` con pruebas unitarias y de integraciÃ³n.  

Cada mÃ³dulo estÃ¡ diseÃ±ado siguiendo el principio de **separaciÃ³n de responsabilidades** (*Separation of Concerns*), lo que facilita el mantenimiento y la escalabilidad del proyecto.

---

## ğŸ§© Archivos importantes

### `.github/workflows/ci.yml`
Ejemplo bÃ¡sico del pipeline de CI/CD:
```yaml
name: Node.js CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Use Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 18
      - run: npm install
      - run: npm test -- --coverage
```
## ğŸ§­ System Usability Scale (SUS)

El **System Usability Scale (SUS)** es un mÃ©todo estandarizado que permite evaluar la facilidad de uso percibida por los usuarios respecto al sistema **Revisor AutomÃ¡tico de Escritura AcadÃ©mica**.

| Indicador | Resultado |
|------------|------------|
| **Puntaje promedio SUS** | **63 / 100** |

### ğŸ“Š InterpretaciÃ³n del resultado
Un puntaje de **63** indica una **usabilidad moderada**, ligeramente por debajo del promedio (68), lo que sugiere que el sistema es **funcional**, pero **requiere mejoras en la experiencia de usuario** para alcanzar un nivel de usabilidad superior.

### ğŸ’¡ RecomendaciÃ³n
> **Mejorar las preguntas a nivel de todo tipo de usuario**, buscando un lenguaje mÃ¡s claro, inclusivo y comprensible, que facilite la interacciÃ³n sin importar el nivel de conocimiento tÃ©cnico del evaluador.
ğŸ“ *Archivo fuente:* [`EvaluaciÃ³n de Usabilidad - Revisor AcadÃ©mico.csv`](https://drive.google.com/file/d/16p3Altjp-7FwlvOwvJn33B_79qZk5G2w/view?usp=drive_link)


---
## ğŸ§  EvaluaciÃ³n de Usabilidad segÃºn Nielsen

La **EvaluaciÃ³n de Usabilidad basada en las HeurÃ­sticas de Nielsen** se centrÃ³ en analizar la interfaz y la experiencia del usuario bajo los **10 principios heurÃ­sticos** propuestos por Jakob Nielsen.

### ğŸ” Objetivo
Identificar problemas de usabilidad en el sistema y proponer mejoras que optimicen la interacciÃ³n usuarioâ€“interfaz.

### ğŸ§¾ Resultados
El anÃ¡lisis se realizÃ³ considerando aspectos como **visibilidad del estado del sistema**, **control y libertad del usuario**, **consistencia**, **prevenciÃ³n de errores**, entre otros.

ğŸ“ *Archivo fuente:* [`EvaluaciÃ³n de Usabilidad - Revisor AcadÃ©mico.csv`](https://drive.google.com/file/d/1Ry_TNSTIg5i49Ath7eS29GuZf2HnWByc/view?usp=drive_link)

### ğŸ’¡ ConclusiÃ³n general
> La evaluaciÃ³n mostrÃ³ un **buen cumplimiento de los principios heurÃ­sticos**, pero se recomienda fortalecer la **retroalimentaciÃ³n visual y los mensajes de ayuda**, especialmente en etapas donde el usuario realiza correcciones o anÃ¡lisis mÃ¡s detallados.

---
---
---
## ğŸ“ Licencia

Este proyecto estÃ¡ bajo la licencia **MIT**.



